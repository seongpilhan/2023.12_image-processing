{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPos0UEGPweqAurqH8TQahm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from PIL import Image\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Custom Dataset Class\n","class CustomDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir)]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert('L')  # Convert to grayscale\n","        label = 0 if 'COVID' in img_path else 1  # Assuming 'COVID' as class 0, 'Pneumonia' as class 1\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label, img_path  # Returning image path for visualization\n","\n","# Define Transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel grayscale\n","    transforms.ToTensor(),\n","])\n","\n","# Create Datasets\n","covid_train_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/train\", transform=transform)\n","pneumonia_train_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/Pneumonia_PSD/train\", transform=transform)\n","covid_test_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/test\", transform=transform)\n","pneumonia_test_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/Pneumonia_PSD/test\", transform=transform)\n","\n","# Print unique image paths in the training dataset\n","unique_train_paths = set(covid_train_dataset.image_paths + pneumonia_train_dataset.image_paths)\n","print(\"Unique training image paths:\", len(unique_train_paths))\n","\n","# Combine Datasets\n","train_dataset = torch.utils.data.ConcatDataset([covid_train_dataset, pneumonia_train_dataset])\n","test_dataset = torch.utils.data.ConcatDataset([covid_test_dataset, pneumonia_test_dataset])\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Print file paths and labels for the first few samples\n","for i in range(5):\n","    image, label, img_path = train_dataset[i]\n","    print(f\"File Path: {img_path}, Label: {label}\")\n","\n","# Check dataset lengths\n","print(\"Length of Train Dataset:\", len(train_dataset))\n","print(\"Length of Test Dataset:\", len(test_dataset))\n","\n","# Define AlexNet Model\n","alexnet = models.alexnet(pretrained=True)\n","\n","# Modify the first layer to accept a single-channel input\n","alexnet.features[0] = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n","\n","# Modify the last layer to match the number of classes (2 in this case)\n","num_ftrs = alexnet.classifier[6].in_features\n","alexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n","\n","# Define Loss Function and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)\n","\n","# Training Loop with tqdm progress bar\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","alexnet.to(device)\n","\n","for epoch in range(num_epochs):\n","    alexnet.train()\n","    running_loss = 0.0\n","    for inputs, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = alexnet(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n","\n","# Evaluation\n","alexnet.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels, _ in tqdm(test_loader, desc=\"Testing\"):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        outputs = alexnet(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WfEj_6SxbHX","executionInfo":{"status":"ok","timestamp":1701576604293,"user_tz":-540,"elapsed":102971,"user":{"displayName":"윤재영","userId":"15924818656922945946"}},"outputId":"00b2687b-79b1-492a-f39e-88a1471e0236"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Unique training image paths: 2000\n","File Path: /content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/train/COVID_psd_10.png, Label: 0\n","File Path: /content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/train/COVID_psd_104.png, Label: 0\n","File Path: /content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/train/COVID_psd_67.png, Label: 0\n","File Path: /content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/train/COVID_psd_107.png, Label: 0\n","File Path: /content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_PSD/train/COVID_psd_22.png, Label: 0\n","Length of Train Dataset: 2000\n","Length of Test Dataset: 690\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/10: 100%|██████████| 63/63 [00:09<00:00,  6.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.702997296575516\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 63/63 [00:09<00:00,  6.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 0.6956584538732257\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 63/63 [00:10<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 0.6932180855009291\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 63/63 [00:09<00:00,  6.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 0.6936784906992837\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10: 100%|██████████| 63/63 [00:10<00:00,  6.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.6936320227289957\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10: 100%|██████████| 63/63 [00:09<00:00,  6.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 0.6922959392032926\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10: 100%|██████████| 63/63 [00:09<00:00,  6.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 0.6912913369754005\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10: 100%|██████████| 63/63 [00:09<00:00,  6.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 0.6915018615268526\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10: 100%|██████████| 63/63 [00:09<00:00,  6.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 0.6923836706176637\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10: 100%|██████████| 63/63 [00:09<00:00,  6.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 0.6921990258353097\n"]},{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 22/22 [00:02<00:00,  8.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 52.90%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}