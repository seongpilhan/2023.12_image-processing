{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLxyFgnlwstP","executionInfo":{"status":"ok","timestamp":1701607333875,"user_tz":-540,"elapsed":533186,"user":{"displayName":"윤재영","userId":"15924818656922945946"}},"outputId":"772fe3b9-5a58-404c-a218-3f53f7d646d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:00<00:00, 81.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.6267868729810866\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 0.4415369677165198\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 0.32430870085954666\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 0.21455934903924428\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.13785368694909036\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 0.0791963128934777\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 0.04458626052216878\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 0.03870702791397297\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 0.02754538171436815\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 0.018770790289318752\n"]},{"output_type":"stream","name":"stderr","text":["                                                        "]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 90.72%\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from PIL import Image\n","import os\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Custom Dataset Class\n","class CustomDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir)]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert('L')  # Convert to grayscale\n","        label = 0 if 'COVID' in img_path else 1  # Assuming 'COVID' as class 0, 'Pneumonia' as class 1\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# Define Transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.Grayscale(num_output_channels=1),  # Convert to 1-channel grayscale\n","    transforms.ToTensor(),\n","])\n","\n","# Create Datasets\n","covid_train_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_DCT/train\", transform=transform)\n","pneumonia_train_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/Pneumonia_DCT/train\", transform=transform)\n","covid_test_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_DCT/test\", transform=transform)\n","pneumonia_test_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/Pneumonia_DCT/test\", transform=transform)\n","\n","# Combine Datasets\n","train_dataset = torch.utils.data.ConcatDataset([covid_train_dataset, pneumonia_train_dataset])\n","test_dataset = torch.utils.data.ConcatDataset([covid_test_dataset, pneumonia_test_dataset])\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define GoogLeNet Model\n","class GoogLeNetCustomInput(nn.Module):\n","    def __init__(self):\n","        super(GoogLeNetCustomInput, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 3, kernel_size=1)  # New convolutional layer for single-channel to three-channel conversion\n","        self.googlenet = models.googlenet(pretrained=True)\n","        # Modify the last layer to match the number of classes (2 in this case)\n","        num_ftrs = self.googlenet.fc.in_features\n","        self.googlenet.fc = nn.Linear(num_ftrs, 2)\n","\n","    def forward(self, x):\n","        # Expand single-channel input to three channels\n","        x = self.conv1(x)\n","        return self.googlenet(x)\n","\n","googlenet_custom_input = GoogLeNetCustomInput()\n","\n","# Define Loss Function and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(googlenet_custom_input.parameters(), lr=0.001, momentum=0.9)\n","\n","# Training Loop with Progress Bar\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","googlenet_custom_input.to(device)\n","\n","for epoch in range(num_epochs):\n","    googlenet_custom_input.train()\n","    running_loss = 0.0\n","    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = googlenet_custom_input(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n","\n","# Evaluation\n","googlenet_custom_input.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in tqdm(test_loader, desc='Testing', leave=False):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        outputs = googlenet_custom_input(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyOg3RTb3BiCFh1Z9OyuYp6H"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}