{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPxCzU/186B9cOYQoYkS5bQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nLxyFgnlwstP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701533884080,"user_tz":-540,"elapsed":782589,"user":{"displayName":"윤재영","userId":"15924818656922945946"}},"outputId":"070862b4-2da1-45ce-d99e-8fa0ecc97418"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:00<00:00, 149MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.46264091938261004\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 0.13700119122153237\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 0.06168391496416122\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 0.03525674841292794\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.023240581509612855\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 0.018697589318016693\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 0.023711880654214867\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 0.013907530466981587\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 0.010506911243918159\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 0.009485444418036395\n"]},{"output_type":"stream","name":"stderr","text":["                                                        "]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 99.46%\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from PIL import Image\n","import os\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Custom Dataset Class\n","class CustomDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir)]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert('L')  # Convert to grayscale\n","        label = 0 if 'COVID' in img_path else 1  # Assuming 'COVID' as class 0, 'Pneumonia' as class 1\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# Define Transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.Grayscale(num_output_channels=1),  # Convert to 1-channel grayscale\n","    transforms.ToTensor(),\n","])\n","\n","# Create Datasets\n","covid_train_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_RAW/train\", transform=transform)\n","pneumonia_train_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/Pneumonia_RAW/train\", transform=transform)\n","covid_test_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/COVID_RAW/test\", transform=transform)\n","pneumonia_test_dataset = CustomDataset(root_dir=\"/content/drive/My Drive/Colab Notebooks/Image_Processing_Project/Pneumonia_RAW/test\", transform=transform)\n","\n","# Combine Datasets\n","train_dataset = torch.utils.data.ConcatDataset([covid_train_dataset, pneumonia_train_dataset])\n","test_dataset = torch.utils.data.ConcatDataset([covid_test_dataset, pneumonia_test_dataset])\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define GoogLeNet Model\n","class GoogLeNetCustomInput(nn.Module):\n","    def __init__(self):\n","        super(GoogLeNetCustomInput, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 3, kernel_size=1)  # New convolutional layer for single-channel to three-channel conversion\n","        self.googlenet = models.googlenet(pretrained=True)\n","        # Modify the last layer to match the number of classes (2 in this case)\n","        num_ftrs = self.googlenet.fc.in_features\n","        self.googlenet.fc = nn.Linear(num_ftrs, 2)\n","\n","    def forward(self, x):\n","        # Expand single-channel input to three channels\n","        x = self.conv1(x)\n","        return self.googlenet(x)\n","\n","googlenet_custom_input = GoogLeNetCustomInput()\n","\n","# Define Loss Function and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(googlenet_custom_input.parameters(), lr=0.001, momentum=0.9)\n","\n","# Training Loop with Progress Bar\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","googlenet_custom_input.to(device)\n","\n","for epoch in range(num_epochs):\n","    googlenet_custom_input.train()\n","    running_loss = 0.0\n","    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = googlenet_custom_input(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n","\n","# Evaluation\n","googlenet_custom_input.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in tqdm(test_loader, desc='Testing', leave=False):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        outputs = googlenet_custom_input(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"]}]}